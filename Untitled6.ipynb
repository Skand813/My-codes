{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as df\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "df = pd.read_excel(r'/Users/smani/Downloads/skills_taxonomy.xlsx')\n",
    "skills = df[\"skill\"].tolist()\n",
    "skill_l = []\n",
    "for x in skills:\n",
    "    if isinstance(x,str):\n",
    "        for y in x :\n",
    "            if y.isalpha():\n",
    "                skill_l.append(x.lower())\n",
    "                break\n",
    "    else:\n",
    "        pass\n",
    "final_skill = list(dict.fromkeys(skill_l))\n",
    "final_skill = final_skill[:5]\n",
    "base_url  = 'https://en.wikipedia.org/wiki/'\n",
    "nowtime = time.time()\n",
    "f=open(\"WP_scrapnew_\" + str(nowtime) + \".json\", \"w+\")\n",
    "final_data = []\n",
    "for i,s in enumerate(final_skill):\n",
    "    skill_list=[]\n",
    "    url1 = '{}{}'.format(base_url, s)\n",
    "    url2 = '{}{}{}'.format(base_url,s,\"_(disambiguation)\")\n",
    "    call_req= 0\n",
    "    while call_req<5:\n",
    "        try:\n",
    "            resp1 = requests.get(url1, timeout=None, stream=True)\n",
    "        except TimeoutError:\n",
    "            sleep(2)\n",
    "            resp1 = None\n",
    "            continue\n",
    "        call_req = call_req + 1\n",
    "    call_req = 0\n",
    "    while call_req<5:\n",
    "        try:\n",
    "            resp2 = requests.get(url2, timeout=None, stream=True)\n",
    "        except TimeoutError:\n",
    "            sleep(2)\n",
    "            resp2 = None\n",
    "            continue\n",
    "        call_req = call_req + 1\n",
    "    if resp1==None or resp2 ==None:\n",
    "        skill_error_list.append(s)\n",
    "        continue\n",
    "    soup1 = BeautifulSoup(resp1.text, 'lxml')\n",
    "    soup2 = BeautifulSoup(resp2.text, 'lxml')\n",
    "    if resp1.status_code == 200:\n",
    "        for item1 in soup1.select(\"#firstHeading\"):\n",
    "            skill_dict = {'Skill': s, 'URL': url1, 'PageHeading': item1.text}\n",
    "    else:\n",
    "        skill_dict = {'Skill': s, 'URL': \"Web page does not exist\", 'PageHeading': \"NA\"}\n",
    "    if resp2.status_code == 200:\n",
    "        for item2 in soup2.select(\".mw-headline\"):\n",
    "            skill_list.append(item2.text)\n",
    "        # print(skill_list)\n",
    "        skill_dict['Other_use'] = skill_list\n",
    "    else:\n",
    "        skill_dict['Other_use'] = \"NA\"\n",
    "    print(i)\n",
    "    f.write(str(skill_dict) + \",\")\n",
    "    # final_data.append(skill_dict)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as df\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "nowtime = time.time()\n",
    "df = pd.read_csv(r'/Users/smani/scrapy_projects/extra_work/driv2.csv')\n",
    "f=open(\"Driv_\" + str(nowtime) + \".json\", \"w+\")\n",
    "link_s = df[\"links\"].tolist()\n",
    "def drivschool(dlink):\n",
    "    res_list=[]\n",
    "    res_dict =dict()\n",
    "    url = dlink\n",
    "    resp = requests.get(url, timeout=None, stream=True)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    if resp.status_code == 200:\n",
    "        result =soup.select(\".entry-content\")\n",
    "        for i in range(0,len(result)):\n",
    "            res_list.append(result[i].text)\n",
    "        #return(res_list)\n",
    "        name = soup.select('h1')\n",
    "        title = name[0].text\n",
    "        res_dict[\"Centre_Name\"]= title\n",
    "        res_dict[\"Details\"] = res_list\n",
    "        f.write(str(res_dict) + \",\")\n",
    "        return res_dict\n",
    "for links in link_s :\n",
    "    drivschool(links)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_s = df[\"links\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drivschool(dlink):\n",
    "    res_list=[]\n",
    "    res_dict =dict()\n",
    "    url = dlink\n",
    "    resp = requests.get(url, timeout=None, stream=True)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    if resp.status_code == 200:\n",
    "        result =soup.select(\".entry-content\")\n",
    "        for i in range(0,len(result)):\n",
    "            res_list.append(result[i].text)\n",
    "        #return(res_list)\n",
    "        name = soup.select('h1')\n",
    "        title = name[0].text\n",
    "        res_dict[\"Centre_Name\"]= title\n",
    "        res_dict[\"Details\"] = res_list\n",
    "        return res_dict\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centre_Name': 'Happy Tails Driving School Ltd.',\n",
       " 'Details': ['15910 105 Ave, Surrey, V4N 3J4 Canada',\n",
       "  '(778)678-5464 ',\n",
       "  'www.happytailsdrivingschool.ca',\n",
       "  'info@happytailsdrivingschool.ca']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivschool('http://find-a-driving-school.ca/happy-tails-driving-school-ltd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list=[]\n",
    "url = 'https://www.sgi.sk.ca/drivereducator'\n",
    "resp = requests.get(url, timeout=None, stream=True)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 =soup.select('.row details-wrapper ng-scope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = soup.select('.row details-wrapper ng-scope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-852cce54666f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "name[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as df\n",
    "import pandas as pd\n",
    "import requests\n",
    "#from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "#requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'\n",
    "headers = { 'User-Agent' : user_agent }\n",
    "df = pd.read_excel(r'/Users/smani/Downloads/skills_taxonomy.xlsx')\n",
    "skills = df[\"skill\"].tolist()\n",
    "skill_l = []\n",
    "for x in skills:\n",
    "    if isinstance(x,str):\n",
    "        for y in x :\n",
    "            if y.isalpha():\n",
    "                skill_l.append(x.lower())\n",
    "                break\n",
    "    else:\n",
    "        pass\n",
    "final_skill = list(dict.fromkeys(skill_l))\n",
    "final_skill = final_skill[3398:]\n",
    "base_url  = 'https://en.wikipedia.org/wiki/'\n",
    "nowtime = time.time()\n",
    "f=open(\"WP_scrapnew_\" + str(nowtime) + \".json\", \"w+\")\n",
    "final_data = []\n",
    "\n",
    "for i,s in enumerate(final_skill):\n",
    "    skill_list=[]\n",
    "    url1 = '{}{}'.format(base_url, s)\n",
    "    url2 = '{}{}{}'.format(base_url,s,\"_(disambiguation)\")\n",
    "\n",
    "    #proxy_host = \"proxy.crawlera.com\"\n",
    "    #proxy_port = \"8010\"\n",
    "    #proxy_auth = \"<CRAWLERA API KEY>:\" # Make sure to include ':' at the end\n",
    "    #proxies = {\"https\": \"https://{}@{}:{}/\".format(proxy_auth, proxy_host, proxy_port),\n",
    "      #\"http\": \"http://{}@{}:{}/\".format(proxy_auth, proxy_host, proxy_port)}\n",
    "\n",
    "    resp1 = requests.get(url1,timeout = None, headers=headers)\n",
    "    resp2 = requests.get(url2,timeout = None, headers=headers)\n",
    "    soup1 = BeautifulSoup(resp1.text, 'html.parser')\n",
    "    soup2 = BeautifulSoup(resp2.text, 'html.parser')\n",
    "    if resp1.status_code == 200:\n",
    "        for item1 in soup1.select(\"#firstHeading\"):\n",
    "            skill_dict = {'Skill':s, 'URL':url1, 'PageHeading':item1.text}\n",
    "    else :\n",
    "        skill_dict={'Skill':s, 'URL':\"Web page does not exist\", 'PageHeading': \"NA\"}\n",
    "    if resp2.status_code == 200:\n",
    "        for item2 in soup2.select(\".mw-headline\"):\n",
    "            skill_list.append(item2.text)\n",
    "            #print(skill_list)\n",
    "        skill_dict['Other_use']= skill_list\n",
    "    else :\n",
    "        skill_dict['Other_use']= \"NA\"\n",
    "    print(i)\n",
    "    f.write(str(skill_dict)+\",\")\n",
    "        #final_data.append(skill_dict)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "p = re.compile('(?<!\\\\\\\\)\\'')\n",
    "str = p.sub('\\\"', str)\n",
    "\n",
    "with open(\"WP_scrapnew_1.json\") as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open(\"WP_scrapnew_2.json\") as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "with open(\"WP_scrapnew_3.json\") as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "items1 = data1[\"items\"]\n",
    "#print(json.dumps(items1, indent=2))\n",
    "items2 = data2[\"items\"]\n",
    "items3 = data3[\"items\"]\n",
    "\n",
    "listitem = [items1, items2, items3]\n",
    "finaljson = {\"items\" : []}\n",
    "\n",
    "finaljson[\"items\"].append(items1)\n",
    "finaljson[\"items\"].append(items2)\n",
    "finaljson[\"items\"].append(items3)\n",
    "#print(json.dumps(finaljson, indent=2))\n",
    "\n",
    "with open(\"merged123_json.json\", \"w\") as f:\n",
    "    f.write(json.dumps(finaljson, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as df\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "#user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'\n",
    "#headers = { 'User-Agent' : user_agent }\n",
    "df = pd.read_excel(r'/Users/smani/Downloads/skills_taxonomy.xlsx')\n",
    "skills = df[\"skill\"].tolist()\n",
    "#skill_l = []\n",
    "for x in skills:\n",
    "    if isinstance(x,str):\n",
    "        for y in x :\n",
    "            if y.isalpha():\n",
    "                skill_l.append(x.lower())\n",
    "                break\n",
    "    else:\n",
    "        pass\n",
    "final_skill = list(dict.fromkeys(skill_l))\n",
    "\n",
    "with open(\"Fianl_list.json\",\"w\") as f :\n",
    "    json.dump(final_skill,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_skill.index(\"auto_dealership_service_tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28557 - 26322\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "scrape_url = \"https://en.wikipedia.org/wiki/Transport_(disambiguation)\"\n",
    "\n",
    "res = requests.get(scrape_url)\n",
    "soup = bs4.BeautifulSoup(res.text,\"lxml\")\n",
    "\n",
    "items = soup.select(\".mw-parser-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"mw-parser-output\"><p>A <b><a href=\"/wiki/Team\" title=\"Team\">team</a></b> is a group of people or other animals linked in a common purpose.\n",
       "</p><p><b>Team</b> or variants may also refer to:\n",
       "</p>\n",
       "<style data-mw-deduplicate=\"TemplateStyles:r886049878\">.mw-parser-output .tocright{float:right;clear:right;width:auto;background:none;padding:.5em 0 .8em 1.4em;margin-bottom:.5em}.mw-parser-output .tocright-clear-left{clear:left}.mw-parser-output .tocright-clear-both{clear:both}.mw-parser-output .tocright-clear-none{clear:none}</style><div class=\"tocright\" style=\"\"><div aria-labelledby=\"mw-toc-heading\" class=\"toc\" id=\"toc\" role=\"navigation\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2 id=\"mw-toc-heading\">Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n",
       "<ul>\n",
       "<li class=\"toclevel-1 tocsection-1\"><a href=\"#Geography\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Geography</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-2\"><a href=\"#Film,_radio_and_TV\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Film, radio and TV</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-3\"><a href=\"#Music\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Music</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-4\"><a href=\"#Acronyms\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Acronyms</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-5\"><a href=\"#See_also\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">See also</span></a></li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "<h2><span class=\"mw-headline\" id=\"Geography\">Geography</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Team_(disambiguation)&amp;action=edit&amp;section=1\" title=\"Edit section: Geography\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<ul><li><a href=\"/wiki/River_Team\" title=\"River Team\">River Team</a>,  a tributary of the River Tyne in Gateshead, England</li></ul>\n",
       "<h2><span id=\"Film.2C_radio_and_TV\"></span><span class=\"mw-headline\" id=\"Film,_radio_and_TV\">Film, radio and TV</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Team_(disambiguation)&amp;action=edit&amp;section=2\" title=\"Edit section: Film, radio and TV\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<ul><li><a href=\"/wiki/The_Team_(radio_network)\" title=\"The Team (radio network)\">The Team (radio network)</a>, a Canadian sports radio network</li>\n",
       "<li><a href=\"/wiki/The_Team_(TV_series)\" title=\"The Team (TV series)\"><i>The Team</i> (TV series)</a>, a television series in a number of African and Asian countries</li>\n",
       "<li><a href=\"/wiki/The_Team_(2015_TV_series)\" title=\"The Team (2015 TV series)\"><i>The Team</i> (2015 TV series)</a>, a 2015 European crime serial television series</li>\n",
       "<li><a class=\"new\" href=\"/w/index.php?title=The_Team_(reality_show)&amp;action=edit&amp;redlink=1\" title=\"The Team (reality show) (page does not exist)\"><i>The Team</i> (reality show)</a>, a reality show broadcast by <a href=\"/wiki/Channel_One_Russia\" title=\"Channel One Russia\">Channel One Russia</a></li>\n",
       "<li><a href=\"/wiki/The_Team_(Agents_of_S.H.I.E.L.D.)\" title=\"The Team (Agents of S.H.I.E.L.D.)\">\"The Team\" (<i>Agents of S.H.I.E.L.D.</i>)</a>, an episode of the television series <i>Agents of S.H.I.E.L.D.</i></li></ul>\n",
       "<h2><span class=\"mw-headline\" id=\"Music\">Music</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Team_(disambiguation)&amp;action=edit&amp;section=3\" title=\"Edit section: Music\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<ul><li><a href=\"/wiki/Team_(Slovak_band)\" title=\"Team (Slovak band)\">Team (Slovak band)</a>, a Slovak pop/rock music band</li>\n",
       "<li><a href=\"/wiki/Team_(American_band)\" title=\"Team (American band)\">Team (American band)</a></li>\n",
       "<li><a href=\"/wiki/Team_(Iggy_Azalea_song)\" title=\"Team (Iggy Azalea song)\">\"Team\" (Iggy Azalea song)</a></li>\n",
       "<li>\"Team\", a song by Beverly Gould-Copeland from the Shining Time Station episode <i>Schemer Goes Camping\"</i></li>\n",
       "<li><a href=\"/wiki/Team_(Lorde_song)\" title=\"Team (Lorde song)\">\"Team\" (Lorde song)</a>, from Lorde's 2013 album <i>Pure Heroine</i></li>\n",
       "<li><a class=\"mw-redirect\" href=\"/wiki/The_Team_(band)\" title=\"The Team (band)\">The Team (band)</a>, an American hip hop band</li></ul>\n",
       "<h2><span class=\"mw-headline\" id=\"Acronyms\">Acronyms</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Team_(disambiguation)&amp;action=edit&amp;section=4\" title=\"Edit section: Acronyms\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<ul><li><a href=\"/wiki/The_European_Alliance_of_EU-critical_Movements\" title=\"The European Alliance of EU-critical Movements\">The European Alliance of EU-critical Movements</a>,  Eurosceptic alliance</li>\n",
       "<li>TEAM <a href=\"/wiki/The_Electors%27_Action_Movement\" title=\"The Electors' Action Movement\">The Electors' Action Movement</a>, a municipal political party in Vancouver, British Columbia</li>\n",
       "<li><a class=\"mw-redirect\" href=\"/wiki/The_Evangelical_Alliance_Mission\" title=\"The Evangelical Alliance Mission\">The Evangelical Alliance Mission</a>, an evangelical Christian missionary organization</li>\n",
       "<li><a class=\"mw-redirect\" href=\"/wiki/Transmission_Electron_Aberration-corrected_Microscope\" title=\"Transmission Electron Aberration-corrected Microscope\">Transmission Electron Aberration-corrected Microscope</a>, a research project aiming to develop a very high resolution electron microscope</li>\n",
       "<li><a href=\"/wiki/TEAM_Linhas_A%C3%A9reas\" title=\"TEAM Linhas Aéreas\">TEAM Linhas Aéreas</a>, an airline based at Jacarepagua Airport in Rio de Janeiro, Brazil</li>\n",
       "<li><i>Tessera Europea di Assicurazione Malattia</i>, Italian for the <a href=\"/wiki/European_Health_Insurance_Card\" title=\"European Health Insurance Card\">European Health Insurance Card</a></li>\n",
       "<li>The Emigration Action Movement, ran in the <a href=\"/wiki/1960_Cork_City_Council_election\" title=\"1960 Cork City Council election\">1960 Cork City Council election</a>, including future Lord Mayor T. P. Leahy</li></ul>\n",
       "<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Team_(disambiguation)&amp;action=edit&amp;section=5\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<ul><li><a href=\"/wiki/Teem\" title=\"Teem\">Teem</a> a lemon-lime-flavored soft drink</li>\n",
       "<li><a class=\"mw-redirect mw-disambig\" href=\"/wiki/TEAMS_(disambiguation)\" title=\"TEAMS (disambiguation)\">TEAMS (disambiguation)</a></li></ul>\n",
       "<table class=\"mbox-small plainlinks sistersitebox\" role=\"presentation\" style=\"background-color:#f9f9f9;border:1px solid #aaa;color:#000\">\n",
       "<tbody><tr>\n",
       "<td class=\"mbox-image\"><img alt=\"\" class=\"noviewer\" data-file-height=\"512\" data-file-width=\"512\" decoding=\"async\" height=\"40\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/40px-Wiktionary-logo-en-v2.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/60px-Wiktionary-logo-en-v2.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/99/Wiktionary-logo-en-v2.svg/80px-Wiktionary-logo-en-v2.svg.png 2x\" width=\"40\"/></td>\n",
       "<td class=\"mbox-text plainlist\">Look up <i><b><a class=\"extiw\" href=\"https://en.wiktionary.org/wiki/team\" title=\"wiktionary:team\">team</a></b></i> in Wiktionary, the free dictionary.</td></tr>\n",
       "</tbody></table>\n",
       "<style data-mw-deduplicate=\"TemplateStyles:r889293728\">.mw-parser-output table.dmbox{clear:both;margin:0.9em 1em;border-top:1px solid #ccc;border-bottom:1px solid #ccc;background-color:transparent}</style>\n",
       "<table class=\"metadata plainlinks dmbox dmbox-disambig\" id=\"disambigbox\" role=\"presentation\" style=\"\">\n",
       "<tbody><tr>\n",
       "<td class=\"mbox-image\" style=\"padding: 2px 0 2px 0.4em;\"> <a class=\"image\" href=\"/wiki/File:Disambig_gray.svg\"><img alt=\"Disambiguation icon\" data-file-height=\"168\" data-file-width=\"220\" decoding=\"async\" height=\"23\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/5/5f/Disambig_gray.svg/30px-Disambig_gray.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/5/5f/Disambig_gray.svg/45px-Disambig_gray.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/5/5f/Disambig_gray.svg/60px-Disambig_gray.svg.png 2x\" width=\"30\"/></a></td>\n",
       "<td class=\"mbox-text\" style=\"padding: 0.25em 0.4em; font-style: italic;\"> <div class=\"shortdescription nomobile noexcerpt noprint searchaux\" style=\"display:none\">Disambiguation page providing links to topics that could be referred to by the same search term</div>This <a href=\"/wiki/Help:Disambiguation\" title=\"Help:Disambiguation\">disambiguation</a> page lists  articles associated with the title <b>Team</b>. <br/> <small>If an <a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Team_(disambiguation)&amp;namespace=0\">internal link</a> led you here, you may wish to change the link to point directly to the intended article.</small> </td>\n",
       "</tr>\n",
       "</tbody></table>\n",
       "<!-- \n",
       "NewPP limit report\n",
       "Parsed by mw2260\n",
       "Cached time: 20200902022930\n",
       "Cache expiry: 2592000\n",
       "Dynamic content: false\n",
       "Complications: []\n",
       "CPU time usage: 0.156 seconds\n",
       "Real time usage: 0.226 seconds\n",
       "Preprocessor visited node count: 1366/1000000\n",
       "Post‐expand include size: 6314/2097152 bytes\n",
       "Template argument size: 1608/2097152 bytes\n",
       "Highest expansion depth: 16/40\n",
       "Expensive parser function count: 1/500\n",
       "Unstrip recursion depth: 0/20\n",
       "Unstrip post‐expand size: 626/5000000 bytes\n",
       "Lua time usage: 0.029/10.000 seconds\n",
       "Lua memory usage: 1.2 MB/50 MB\n",
       "Number of Wikibase entities loaded: 0/400\n",
       "-->\n",
       "<!--\n",
       "Transclusion expansion time report (%,ms,calls,template)\n",
       "100.00%  191.786      1 -total\n",
       " 64.58%  123.864      1 Template:Disambiguation\n",
       " 49.00%   93.984      1 Template:Dmbox\n",
       " 23.10%   44.310      1 Template:Wiktionary\n",
       " 20.73%   39.750      1 Template:Sister_project\n",
       " 19.56%   37.519      3 Template:Main_other\n",
       " 18.32%   35.129      1 Template:Side_box\n",
       " 17.15%   32.884      1 Template:Disambiguation_page_short_description\n",
       " 15.79%   30.283      1 Template:Short_description\n",
       " 14.41%   27.644      1 Template:Category_handler\n",
       "-->\n",
       "<!-- Saved in parser cache with key enwiki:pcache:idhash:1567917-0!canonical and timestamp 20200902022931 and revision id 934643448\n",
       " -->\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "scrape_url = \"https://en.wikipedia.org/wiki/Team_(disambiguation)\"\n",
    "\n",
    "res = requests.get(scrape_url)\n",
    "soup = bs4.BeautifulSoup(res.text,\"lxml\")\n",
    "\n",
    "items = soup.select(\".mw-headline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: Team Liquid\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: Edit section: Geography\n",
      "Title: River Team\n",
      "Title: Edit section: Film, radio and TV\n",
      "Title: The Team (radio network)\n",
      "Title: The Team (TV series)\n",
      "Title: The Team (2015 TV series)\n",
      "Title: The Team (reality show) (page does not exist)\n",
      "Title: Channel One Russia\n",
      "Title: The Team (Agents of S.H.I.E.L.D.)\n",
      "Title: Edit section: Music\n",
      "Title: Team (Slovak band)\n",
      "Title: Team (American band)\n",
      "Title: Team (Iggy Azalea song)\n",
      "Title: Team (Lorde song)\n",
      "Title: The Team (band)\n",
      "Title: Edit section: Acronyms\n",
      "Title: The European Alliance of EU-critical Movements\n",
      "Title: The Electors' Action Movement\n",
      "Title: The Evangelical Alliance Mission\n",
      "Title: Transmission Electron Aberration-corrected Microscope\n",
      "Title: TEAM Linhas Aéreas\n",
      "Title: European Health Insurance Card\n",
      "Title: 1960 Cork City Council election\n",
      "Title: Edit section: See also\n",
      "Title: Teem\n",
      "Title: TEAMS (disambiguation)\n",
      "Title: wiktionary:team\n",
      "Title: None\n",
      "Title: Help:Disambiguation\n",
      "Title: None\n",
      "Title: None\n",
      "Title: Help:Category\n",
      "Title: Category:Disambiguation pages\n",
      "Title: Category:Disambiguation pages with short descriptions\n",
      "Title: Category:Short description is different from Wikidata\n",
      "Title: Category:All article disambiguation pages\n",
      "Title: Category:All disambiguation pages\n",
      "Title: Discussion about edits from this IP address [n]\n",
      "Title: A list of edits made from this IP address [y]\n",
      "Title: You are encouraged to create an account and log in; however, it is not mandatory\n",
      "Title: You're encouraged to log in; however, it's not mandatory. [o]\n",
      "Title: View the content page [c]\n",
      "Title: Discuss improvements to the content page [t]\n",
      "Title: None\n",
      "Title: Edit this page [e]\n",
      "Title: Past revisions of this page [h]\n",
      "Title: Visit the main page\n",
      "Title: Visit the main page [z]\n",
      "Title: Guides to browsing Wikipedia\n",
      "Title: Articles related to current events\n",
      "Title: Visit a randomly selected article [x]\n",
      "Title: Learn about Wikipedia and how it works\n",
      "Title: How to contact Wikipedia\n",
      "Title: Support us by donating to the Wikimedia Foundation\n",
      "Title: Guidance on how to use and edit Wikipedia\n",
      "Title: Learn how to edit Wikipedia\n",
      "Title: The hub for editors\n",
      "Title: A list of recent changes to Wikipedia [r]\n",
      "Title: Add images or other media for use on Wikipedia\n",
      "Title: List of all English Wikipedia pages containing links to this page [j]\n",
      "Title: Recent changes in pages linked from this page [k]\n",
      "Title: Upload files [u]\n",
      "Title: A list of all special pages [q]\n",
      "Title: Permanent link to this revision of this page\n",
      "Title: More information about this page\n",
      "Title: Information on how to cite this page\n",
      "Title: Structured data on this page hosted by Wikidata [g]\n",
      "Title: Download this page as a PDF file\n",
      "Title: Printable version of this page [p]\n",
      "Title: تیم (ابهام‌زدایی) – Persian\n",
      "Title: Team – French\n",
      "Title: TEAM – Korean\n",
      "Title: צוות – Hebrew\n",
      "Title: チーム (曖昧さ回避) – Japanese\n",
      "Title: Team – Polish\n",
      "Title: Team – Portuguese\n",
      "Title: Edit interlanguage links\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: wmf:Privacy policy\n",
      "Title: Wikipedia:About\n",
      "Title: Wikipedia:General disclaimer\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n",
      "Title: None\n"
     ]
    }
   ],
   "source": [
    "for i in result :\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        #print(\"Inner Text: {}\".format(link.text))\n",
    "        print(\"Title: {}\".format(link.get(\"title\")))\n",
    "        #print(\"href: {}\".format(link.get(\"href\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: json-excel-converter[xlsxwriter] in /opt/anaconda3/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: xlsxwriter<2.0,>=1.2; extra == \"xlsxwriter\" in /opt/anaconda3/lib/python3.7/site-packages (from json-excel-converter[xlsxwriter]) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install json-excel-converter[xlsxwriter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from json_excel_converter import Converter \n",
    "from json_excel_converter.xlsx import Writer\n",
    "\n",
    "df = pd.read_json('/Users/smani/Downloads/data.json')\n",
    "conv = Converter()\n",
    "conv.convert(data, Writer(file='/Users/smani/Downloads/Complete_WP1.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from json_excel_converter import Converter \n",
    "from json_excel_converter.xlsx import Writer\n",
    "\n",
    "df = pd.read_json('/Users/smani/Downloads/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 2 column 1 (char 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-de39fdc9f96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/smani/Downloads/Complete_WP_1.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-de39fdc9f96a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/smani/Downloads/Complete_WP_1.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 2 column 1 (char 3)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open(\"/Users/smani/Downloads/Complete_WP_1.json\") as f:\n",
    "  df = pd.DataFrame([json.loads(l) for l in f.readlines()])\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-724085411b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m',}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m',]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m']'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/smani/Downloads/Complete_WP_1.json','r') as f:\n",
    "    s = f.read()\n",
    "    s = s.replace('','')\n",
    "    s = s.replace('\\n','')\n",
    "    s = s.replace(',}','}')\n",
    "    s = s.replace(',]',']')\n",
    "    data = json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
